{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression from scratch, Iris\n",
    "\n",
    "Adapted from Pellarolo, Martin.  [\"Logistic Regression from scratch in Python.\"](https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac) Medium. Feb. 22, 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data  #[:,:2]\n",
    "\n",
    "# two non-linearly separable classes are labeled with same category for binary classification problem\n",
    "y = (iris.target != 0) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equations\n",
    "\n",
    "$ h_\\theta(x) = g(\\theta^Tx) $\n",
    "\n",
    "$ z = \\theta^Tx$\n",
    "\n",
    "Sigmoid\n",
    "\n",
    "$g(z) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "Loss Function\n",
    "\n",
    "$h = g(X\\theta)$\n",
    "\n",
    "$J(\\theta) = \\frac{1}{m}*(-y^T log(h) - (1-y)^T log(1-h))$\n",
    "\n",
    "Gradient Descent (partial derivative of loss function)\n",
    "\n",
    "$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m}X^T(g(X\\theta)-y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Union\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.01, num_iter=1e5, fit_intercept=True, verbose=False):\n",
    "        \"\"\"Instantiate logistic regression model\n",
    "        \n",
    "        Arguments:\n",
    "            lr (float):\n",
    "            num_iter Union[float, int]: \n",
    "            fit_intercept (bool):\n",
    "            verbose (bool):\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.num_iter = int(num_iter)\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def _add_intercept(self, X):\n",
    "        \"\"\"Add intercept column of ones\"\"\"\n",
    "        intercept = np.ones((X.shape[0],1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"logistic function, aka sigmoid.  Gives outputs between 0 and 1 for all values of X.\n",
    "        \n",
    "        Arguments:\n",
    "            z: matrix of inputs dot multiplied by weights\n",
    "        \n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def _gradient_descent(self, X, y):\n",
    "        \"\"\"Minimize the loss function to 'fit' weights through the use of gradient descent\n",
    "        \n",
    "        Arguments:\n",
    "            X (np.array): independent variables\n",
    "            y (np.array): target variable\n",
    "            \n",
    "        Returns (np.array): updated weights\n",
    "        \"\"\"\n",
    "        z = np.dot(X, self.theta)  # X\\theta\n",
    "        h = self._sigmoid(z)  \n",
    "        \n",
    "        # derivative of the loss function with respect to each weight\n",
    "        gradient = np.dot(X.T, (h-y)) / y.shape[0]  #y.size\n",
    "        self.theta -= self.lr * gradient   \n",
    "        return self.theta\n",
    "    \n",
    "    def _loss(self, h, y):\n",
    "        \"\"\"Measure how parameters/weights (theta) perform against actual targets\n",
    "        \n",
    "        Arguments:\n",
    "            h (np.array): independent variables transformed by weights and sigmoid\n",
    "            y (np.array): target variable\n",
    "            \n",
    "        Returns (np.array): loss of predicted vs actual values\n",
    "        \"\"\"\n",
    "        return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Adjust weights through the use of gradient descent to minimize loss function\n",
    "        \n",
    "        Arguments:\n",
    "            X (np.array): independent variables\n",
    "            y (np.array): target variable\n",
    "        \n",
    "        Returns (np.array): final weights\n",
    "        \"\"\"\n",
    "        if self.fit_intercept:\n",
    "            X = self._add_intercept(X)\n",
    "            \n",
    "        # weights initialization\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "        # gradient descent\n",
    "        for i in range(self.num_iter):\n",
    "            self.theta = self._gradient_descent(X,y)\n",
    "            \n",
    "            if (self.verbose == True and i% 1e4 == 0):\n",
    "                z = np.dot(X,self.theta)\n",
    "                h = self._sigmoid(z)\n",
    "                loss = self._loss(h,y)\n",
    "                print(f\"loss: {loss}\\ttheta: {self.theta}\\t\")\n",
    "                \n",
    "    def predict_prob(self, X):\n",
    "        \"\"\"Use trained weights to predict probability of an array of independent variables\n",
    "        \n",
    "        Arguments:\n",
    "            X (np.array): independent variables\n",
    "            \n",
    "        Returns (np.array): predictions of target variable\n",
    "        \"\"\"\n",
    "        if self.fit_intercept:\n",
    "            X = self._add_intercept(X)\n",
    "            \n",
    "        return self._sigmoid(np.dot(X, self.theta))\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \"\"\"Determine prediction based on probability vs a threshold\n",
    "        \n",
    "        Arguments:\n",
    "            X (np.array): independent variables\n",
    "            threshold (float): Threshold at which classification is positive vs negative\n",
    "            \n",
    "        Returns (np.array): predictions of target variable\n",
    "        \"\"\"\n",
    "        return self.predict_prob(X)>=threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5518148780651356\ttheta: [0.01666667 0.1253     0.0386     0.13916667 0.05176667]\t\n",
      "loss: 0.0009260487284893174\ttheta: [-0.50737031 -0.80046713 -2.79745681  4.35579803  2.00574432]\t\n",
      "loss: 0.0004964360803264601\ttheta: [-0.56140932 -0.88897972 -3.11101408  4.85051629  2.25210803]\t\n",
      "loss: 0.00034433226750420003\ttheta: [-0.59392067 -0.94300082 -3.29764476  5.14829545  2.40300338]\t\n",
      "loss: 0.00026543657803717035\ttheta: [-0.61746509 -0.9824939  -3.43135472  5.36342423  2.51316817]\t\n",
      "loss: 0.000216826367785434\ttheta: [-0.63602952 -1.01385351 -3.53574369  5.53252175  2.60040554]\t\n",
      "loss: 0.0001837400049202278\ttheta: [-0.65140793 -1.03997669 -3.62143955  5.67214256  2.67284486]\t\n",
      "loss: 0.00015970148734077025\ttheta: [-0.66456568 -1.06243101 -3.69415725  5.79121832  2.73490567]\t\n",
      "loss: 0.0001414114307579239\ttheta: [-0.67608352 -1.0821639  -3.75732965  5.8951302   2.789267  ]\t\n",
      "loss: 0.00012700778779256526\ttheta: [-0.6863387  -1.09979333 -3.81318244  5.98737661  2.83767951]\t\n",
      "loss: 0.00011535810515011869\ttheta: [-0.69559048 -1.11574549 -3.86324189  6.07036266  2.88135204]\t\n",
      "loss: 0.0001057331193741963\ttheta: [-0.70402491 -1.13032721 -3.90860067  6.14581424  2.92115536]\t\n",
      "loss: 9.76414839212886e-05\ttheta: [-0.71178014 -1.14376696 -3.95006818  6.21501263  2.95773813]\t\n",
      "loss: 9.073977755222316e-05\ttheta: [-0.71896163 -1.15623966 -3.98826084  6.27893566  2.99159688]\t\n",
      "loss: 8.478056320217928e-05\ttheta: [-0.72565178 -1.16788225 -4.02365903  6.33834684  3.02312038]\t\n",
      "loss: 7.95809390840595e-05\ttheta: [-0.7319162  -1.17880407 -4.05664442  6.39385397  3.05261887]\t\n",
      "loss: 7.500271919985764e-05\ttheta: [-0.73780804 -1.18909385 -4.08752534  6.4459489   3.080344  ]\t\n",
      "loss: 7.093951044517733e-05\ttheta: [-0.74337096 -1.1988246  -4.11655445  6.4950354   3.10650277]\t\n",
      "loss: 6.730803600746006e-05\ttheta: [-0.74864126 -1.20805718 -4.14394141  6.54144904  3.13126758]\t\n",
      "loss: 6.404215936840872e-05\ttheta: [-0.75364948 -1.21684286 -4.16986213  6.58547183  3.15478353]\t\n",
      "loss: 6.108867514137177e-05\ttheta: [-0.75842155 -1.22522522 -4.19446564  6.62734306  3.177174  ]\t\n",
      "loss: 5.840428499476615e-05\ttheta: [-0.76297968 -1.23324167 -4.2178793   6.66726753  3.19854472]\t\n",
      "loss: 5.595338623320507e-05\ttheta: [-0.76734305 -1.24092456 -4.24021286  6.70542193  3.21898706]\t\n",
      "loss: 5.370642877297961e-05\ttheta: [-0.77152834 -1.24830205 -4.2615615   6.74195976  3.2385805 ]\t\n",
      "loss: 5.163867679859466e-05\ttheta: [-0.77555014 -1.25539881 -4.28200836  6.77701523  3.25739464]\t\n",
      "loss: 4.97292632110436e-05\ttheta: [-0.77942128 -1.2622366  -4.30162645  6.8107064   3.27549076]\t\n",
      "loss: 4.796045903210829e-05\ttheta: [-0.78315314 -1.26883468 -4.32048026  6.84313765  3.29292311]\t\n",
      "loss: 4.631710274052459e-05\ttheta: [-0.78675583 -1.2752102  -4.33862703  6.87440173  3.30973997]\t\n",
      "loss: 4.4786150064451636e-05\ttheta: [-0.79023838 -1.28137852 -4.35611778  6.90458144  3.32598446]\t\n",
      "loss: 4.3356315524772443e-05\ttheta: [-0.7936089  -1.28735341 -4.3729982   6.93375101  3.3416953 ]\t\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(lr=0.1, num_iter=3e5, fit_intercept=True, verbose=True)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.79687435, -1.29314673, -4.38930778,  6.96197446,  3.35690585])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Parameters: [[ 0.44501376 -0.89999242  2.32353827  0.97345836]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X,y)\n",
    "predicted_classes = model.predict(X)\n",
    "accuracy = accuracy_score(y, predicted_classes)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "parameters = model.coef_\n",
    "print(f\"Parameters: {parameters}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Algorithms",
   "language": "python",
   "name": "algorithms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
